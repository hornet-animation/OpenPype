"""
Requires:
    environment     -> SAPUBLISH_INPATH
    environment     -> SAPUBLISH_OUTPATH

Provides:
    context         -> returnJsonPath (str)
    context         -> project
    context         -> asset
    instance        -> destination_list (list)
    instance        -> representations (list)
    instance        -> source (list)
    instance        -> representations
"""

import os
import pyblish.api
from avalon import io
import json
import logging
import clique

log = logging.getLogger("collector")


class CollectContextDataSAPublish(pyblish.api.ContextPlugin):
    """
    Collecting temp json data sent from a host context
    and path for returning json data back to hostself.
    """

    label = "Collect Context - SA Publish"
    order = pyblish.api.CollectorOrder - 0.49
    hosts = ["standalonepublisher"]

    def process(self, context):
        # get json paths from os and load them
        io.install()

        # Load presets
        presets = context.data.get("presets")
        if not presets:
            from pype.api import config

            presets = config.get_presets()

        project = io.find_one({"type": "project"})
        context.data["project"] = project

        # get json file context
        input_json_path = os.environ.get("SAPUBLISH_INPATH")

        with open(input_json_path, "r") as f:
            in_data = json.load(f)
            self.log.debug(f"_ in_data: {in_data}")

        self.asset_name = in_data["asset"]
        self.family = in_data["family"]
        asset = io.find_one({"type": "asset", "name": self.asset_name})
        context.data["asset"] = asset

        # exception for editorial
        if "editorial" in self.family:
            # avoid subset name duplicity
            if not context.data.get("subsetNamesCheck"):
                context.data["subsetNamesCheck"] = list()

            in_data_list = list()
            representations = in_data.pop("representations")
            for repr in representations:
                in_data_copy = in_data.copy()
                ext = repr["ext"][1:]
                subset = in_data_copy["subset"]
                # filter out non editorial files
                if ext not in ["edl", "xml"]:
                    in_data_copy["representations"] = [repr]
                    in_data_copy["subset"] = f"{ext}{subset}"
                    in_data_list.append(in_data_copy)

                files = repr.pop("files")

                # delete unneeded keys
                delete_repr_keys = ["frameStart", "frameEnd"]
                for k in delete_repr_keys:
                    if repr.get(k):
                        repr.pop(k)

                # convert files to list if it isnt
                if not isinstance(files, list):
                    files = [files]

                self.log.debug(f"_ files: {files}")
                for index, f in enumerate(files):
                    index += 1
                    # copy dictionaries
                    in_data_copy = in_data_copy.copy()
                    repr_new = repr.copy()

                    repr_new["files"] = f
                    repr_new["name"] = ext
                    in_data_copy["representations"] = [repr_new]

                    # create subset Name
                    new_subset = f"{ext}{index}{subset}"
                    while new_subset in context.data["subsetNamesCheck"]:
                        index += 1
                        new_subset = f"{ext}{index}{subset}"

                    context.data["subsetNamesCheck"].append(new_subset)
                    in_data_copy["subset"] = new_subset
                    in_data_list.append(in_data_copy)
                    self.log.info(f"Creating subset: {ext}{index}{subset}")
        else:
            in_data_list = [in_data]

        self.log.debug(f"_ in_data_list: {in_data_list}")

        for in_data in in_data_list:
            # create instance
            self.create_instance(context, in_data)

    def create_instance(self, context, in_data):
        subset = in_data["subset"]

        instance = context.create_instance(subset)

        instance.data.update(
            {
                "subset": subset,
                "asset": self.asset_name,
                "label": subset,
                "name": subset,
                "family": self.family,
                "version": in_data.get("version", 1),
                "frameStart": in_data.get("representations", [None])[0].get(
                    "frameStart", None
                ),
                "frameEnd": in_data.get("representations", [None])[0].get(
                    "frameEnd", None
                ),
                "families": [self.family, "ftrack"],
            }
        )
        self.log.info("collected instance: {}".format(instance.data))
        self.log.info("parsing data: {}".format(in_data))

        instance.data["destination_list"] = list()
        instance.data["representations"] = list()
        instance.data["source"] = "standalone publisher"

        for component in in_data["representations"]:
            component["destination"] = component["files"]
            component["stagingDir"] = component["stagingDir"]

            if isinstance(component["files"], list):
                collections, remainder = clique.assemble(component["files"])
                self.log.debug("collecting sequence: {}".format(collections))
                instance.data["frameStart"] = int(component["frameStart"])
                instance.data["frameEnd"] = int(component["frameEnd"])
                instance.data["fps"] = int(component["fps"])

            if component["preview"]:
                instance.data["families"].append("review")
                instance.data["repreProfiles"] = ["h264"]
                component["tags"] = ["review"]
                self.log.debug("Adding review family")

            instance.data["representations"].append(component)
